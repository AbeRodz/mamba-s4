{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssm import SSM\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = SSM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_t = torch.randn((2, 512, 64), device=\"cuda\", dtype=torch.float32)\n",
    "A_bar = torch.randn((2, 512, 64, 2), device=\"cuda\", dtype=torch.float32)\n",
    "B_bar_x = torch.randn_like(A_bar)\n",
    "C = torch.randn((2, 64, 2), device=\"cuda\", dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b ,c = space.random_SSM(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.4678],\n",
       "        [0.0305, 0.6055]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6504],\n",
       "        [0.9368]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3064, 0.2199]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.6850, 0.9007],\n",
       "         [0.0587, 1.8880]]),\n",
       " tensor([[1.2951],\n",
       "         [1.3718]]),\n",
       " tensor([[0.3064, 0.2199]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space.discretize(a,b,c,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.6488, 1.5965],\n",
       "         [1.0310, 1.8321]]),\n",
       " tensor([[1.8556],\n",
       "         [2.0569]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space.discretize_zoh(a,b,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.ones([3])\n",
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_log(float_input, eps=1e-6):\n",
    "        eps = float_input.new_tensor(eps)\n",
    "        real = float_input.abs().maximum(eps).log()\n",
    "        imag = (float_input < 0).to(float_input.dtype) * torch.pi\n",
    "        return torch.complex(real, imag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  TODO READ THE S4 code the issue is on the input dimensionality, seems that einsum might be the answer to this issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure and Dimensions.\n",
    "Finally, we note that structured SSMs are so named because computing them efficiently also requires imposing structure on the A matrix. The most popular form of structure is diagonal which we also use.\n",
    "\n",
    "In this case, the A ∈ ℝN×N, B ∈ ℝN×1, C ∈ ℝ1×N matrices can all be represented by N numbers. \n",
    "\n",
    "To operate over an input sequence x of batch size B and length L with D channels, the SSM is applied independently to each\n",
    "channel.\n",
    "\n",
    "Note that in this case, the total hidden state has dimension DN per input, and computing it over the\n",
    "sequence length requires O(BLDN) time and memory; this is the root of the fundamental efficiency bottleneck\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dimesnions \n",
    " - Input(x) and output(y) are of size BLD\n",
    " - A : (DN)\n",
    " - B : (BLN) \n",
    " - C : (BLN)\n",
    " - Delta : (BLD)\n",
    " - A_BAR, B_BAR : (BLDN) discretize with (Delta,AB)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_scan( h_t: torch.Tensor ,A_bar : torch.Tensor, B_bar: torch.Tensor, C: torch.Tensor):\n",
    "        \n",
    "        # h_t = A_bar * h_t-1 + B_bar*x_t\n",
    "        #y_t =C*h_t\n",
    "\n",
    "        ## heinsen\n",
    "        # x_t = a_t*x_t-1 + b_t\n",
    "\n",
    "        # equivalent notation\n",
    "\n",
    "        # h_t = A_bar_t * h_t-1 + B_bar*x_t\n",
    "        # where x_t is the input sequence hence:\n",
    "        # cat(B_bar,  x_t) = b_t' or b_t prime.\n",
    "        # finally:\n",
    "        # h_t = A_bar_t * h_t-1 + b_t'\n",
    "        \"\"\"\n",
    "        In summary we need to calculate a state space equation (S4) using the heinsen method.\n",
    "\n",
    "        \"\"\"\n",
    "        #b_t_prime =  torch.cat([h_t[..., None], B_bar], dim=-1)\n",
    "        #b_t_prime = torch.matmul(B_bar,h_t)\n",
    "        #b_t_prime = B_bar @ h_t\n",
    "        b_t_prime = torch.einsum(\"bld,bln->bldn\", h_t,B_bar)\n",
    "        log_b_t = complex_log(b_t_prime)\n",
    "        log_a_t = complex_log(A_bar)\n",
    "        a_star = F.pad(torch.cumsum(log_a_t, dim = -1),(1,0))\n",
    "        #a_star = torch.cumsum(log_a_t, dim = -1)\n",
    "        print(log_b_t.shape)\n",
    "        print(a_star.shape)\n",
    "        log_h0_plus_b_star = torch.logcumsumexp(log_b_t - a_star, dim = -1)\n",
    "\n",
    "        log_h = (a_star + log_h0_plus_b_star)[...,1:]\n",
    "        \n",
    "        h = torch.exp(log_h).real\n",
    "        print(h.shape)\n",
    "        y_t = torch.matmul(C, h).squeeze(-1)\n",
    "        #y_t = torch.einsum(\"bnt,bdnt->bdt\", C, h) \n",
    "        return h, y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selective_scan(u, dt, A, B, C):\n",
    "        dA = torch.einsum('bld,dn->bldn', dt, A)\n",
    "        dB_u = torch.einsum('bld,bld,bln->bldn', dt, u, B)\n",
    "        \n",
    "        dA_cumsum = F.pad(dA[:, 1:], (0, 0, 0, 0, 0, 1)).flip(1).cumsum(1).exp().flip(1)\n",
    "        x = dB_u * dA_cumsum\n",
    "        x = x.cumsum(1) / (dA_cumsum + 1e-12)\n",
    "        y = torch.einsum('bldn,bln->bld', x, C)\n",
    "    \n",
    "        return y + u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_in_parallel(coeffs, values):\n",
    "    log_coeffs = complex_log(coeffs)\n",
    "    log_values = complex_log(values)\n",
    "    a_star = F.pad(torch.cumsum(log_coeffs, dim=-1), (1, 0))              # eq (2) in paper\n",
    "    print(log_values.shape)\n",
    "    print(a_star.shape)\n",
    "    log_x0_plus_b_star = torch.logcumsumexp(log_values - a_star, dim=-1)  # eq (7) in paper\n",
    "    log_x = a_star + log_x0_plus_b_star                                   # eq (1) in paper\n",
    "    return torch.exp(log_x).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.Tensor([[1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "einsum(): the number of subscripts in the equation (3) does not match the number of dimensions (2) for operand 0 and no ellipsis was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mparallel_scan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 23\u001b[0m, in \u001b[0;36mparallel_scan\u001b[1;34m(h_t, A_bar, B_bar, C)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mIn summary we need to calculate a state space equation (S4) using the heinsen method.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#b_t_prime =  torch.cat([h_t[..., None], B_bar], dim=-1)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#b_t_prime = torch.matmul(B_bar,h_t)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#b_t_prime = B_bar @ h_t\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m b_t_prime \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbld,bln->bldn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43mB_bar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m log_b_t \u001b[38;5;241m=\u001b[39m complex_log(b_t_prime)\n\u001b[0;32m     25\u001b[0m log_a_t \u001b[38;5;241m=\u001b[39m complex_log(A_bar)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\Documents\\python_stuff\\venv\\Lib\\site-packages\\torch\\functional.py:377\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[1;32m--> 377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    379\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[1;31mRuntimeError\u001b[0m: einsum(): the number of subscripts in the equation (3) does not match the number of dimensions (2) for operand 0 and no ellipsis was given"
     ]
    }
   ],
   "source": [
    "parallel_scan(u,a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2724],\n",
       "        [0.2279]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_in_parallel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcompute_in_parallel\u001b[49m(a,b)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'compute_in_parallel' is not defined"
     ]
    }
   ],
   "source": [
    "compute_in_parallel(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 3 and 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fb \u001b[38;5;241m=\u001b[39mcomplex_log(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mu\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      2\u001b[0m fb\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 3 and 2"
     ]
    }
   ],
   "source": [
    "fb =complex_log(torch.cat([u[..., None], b], dim=-1))\n",
    "fb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = torch.cumsum(complex_log(a), dim = -1)\n",
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000+0.0000j,   0.0000+0.0000j],\n",
       "        [-13.8155-3.1416j,  -1.6094-6.2832j]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb - f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "einsum(): the number of subscripts in the equation (3) does not match the number of dimensions (2) for operand 0 and no ellipsis was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h , y \u001b[38;5;241m=\u001b[39m \u001b[43mparallel_scan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 23\u001b[0m, in \u001b[0;36mparallel_scan\u001b[1;34m(h_t, A_bar, B_bar, C)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mIn summary we need to calculate a state space equation (S4) using the heinsen method.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#b_t_prime =  torch.cat([h_t[..., None], B_bar], dim=-1)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#b_t_prime = torch.matmul(B_bar,h_t)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#b_t_prime = B_bar @ h_t\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m b_t_prime \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbld,bln->bldn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43mB_bar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m log_b_t \u001b[38;5;241m=\u001b[39m complex_log(b_t_prime)\n\u001b[0;32m     25\u001b[0m log_a_t \u001b[38;5;241m=\u001b[39m complex_log(A_bar)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\Documents\\python_stuff\\venv\\Lib\\site-packages\\torch\\functional.py:377\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[1;32m--> 377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    379\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[1;31mRuntimeError\u001b[0m: einsum(): the number of subscripts in the equation (3) does not match the number of dimensions (2) for operand 0 and no ellipsis was given"
     ]
    }
   ],
   "source": [
    "h , y = parallel_scan(u, a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0000e-06],\n",
       "        [1.0000e+00]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0000e-06])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([u[..., None], b], dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_mass(k, b, m):\n",
    "    A = np.array([[0, 1], [-k / m, -b / m]])\n",
    "    B = np.array([[0], [1.0 / m]])\n",
    "    C = np.array([[1.0, 0]])\n",
    "    return torch.Tensor(A), torch.Tensor(B), torch.Tensor(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = example_mass(1,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_force(t):\n",
    "    x = np.sin(10 * t)\n",
    "    return torch.Tensor(x * (x > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = example_force(np.arange(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.Tensor([1,1])\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.],\n",
       "        [-1., -5.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.],\n",
       "        [-1., -5.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((2, 2))\n",
    "y = torch.rand((1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3428, 0.8222]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7660],\n",
       "        [0.8331]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"ij,kj->ik\",X,y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "einsum(): the number of subscripts in the equation (3) does not match the number of dimensions (1) for operand 0 and no ellipsis was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h , y \u001b[38;5;241m=\u001b[39m \u001b[43mparallel_scan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 23\u001b[0m, in \u001b[0;36mparallel_scan\u001b[1;34m(h_t, A_bar, B_bar, C)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mIn summary we need to calculate a state space equation (S4) using the heinsen method.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#b_t_prime =  torch.cat([h_t[..., None], B_bar], dim=-1)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#b_t_prime = torch.matmul(B_bar,h_t)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#b_t_prime = B_bar @ h_t\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m b_t_prime \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbld,bln->bldn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43mB_bar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m log_b_t \u001b[38;5;241m=\u001b[39m complex_log(b_t_prime)\n\u001b[0;32m     25\u001b[0m log_a_t \u001b[38;5;241m=\u001b[39m complex_log(A_bar)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\Documents\\python_stuff\\venv\\Lib\\site-packages\\torch\\functional.py:377\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[1;32m--> 377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    379\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[1;31mRuntimeError\u001b[0m: einsum(): the number of subscripts in the equation (3) does not match the number of dimensions (1) for operand 0 and no ellipsis was given"
     ]
    }
   ],
   "source": [
    "h , y = parallel_scan(u, a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.737088e-05, 4.968198e-05], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e-06, 2.0000e-06],\n",
       "        [6.6002e-15, 1.0000e+00]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0.,   1.],\n",
       "         [-40.,  -5.]]),\n",
       " tensor([[0.],\n",
       "         [1.]]),\n",
       " tensor([[1., 0.]]))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_mass(40,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5646, 0.6442, 0.7174,\n",
       "        0.7833, 0.8415, 0.8912, 0.9320, 0.9636, 0.9854, 0.9975, 0.9996, 0.9917,\n",
       "        0.9738, 0.9463, 0.9093, 0.8632, 0.8085, 0.7457, 0.6755, 0.5985, 0.5155,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "        -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "        -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "        -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5784, 0.6570, 0.7290,\n",
       "        0.7937, 0.8504, 0.8987, 0.9380, 0.9679, 0.9882, 0.9985, 0.9989, 0.9894,\n",
       "        0.9699, 0.9407, 0.9022, 0.8546, 0.7985, 0.7344, 0.6630, 0.5849, 0.5010,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "        -0.0000])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_scan(\n",
    "    h_t: torch.FloatTensor,\n",
    "    A_bar: torch.FloatTensor,\n",
    "    B_bar_x: torch.FloatTensor,\n",
    "    C: torch.FloatTensor,\n",
    "    eps: float = 1e-8,\n",
    ") -> torch.FloatTensor:\n",
    "    \"\"\"\n",
    "    Parallel computation of the selective scan based on the algorithm described in\n",
    "    \"Efficient Parallelization of a Ubiquitous Sequential Computation\". This method\n",
    "    transforms the sequential operation `x_t = a_t * x_{t−1} + b_t` into a form\n",
    "    suitable for parallel processing. It computes `log(x_t) = a_star_t + log(x_0 + b_star_t)`\n",
    "    using parallel cumulative sums, where `a_star_t = cumsum(log(a_t))` and\n",
    "    `b_star_t = logcumsumexp(log(b_t - a_star_t))`. This approach significantly\n",
    "    enhances computational efficiency for large-scale tensor operations. In this method, we use the\n",
    "    above formulation to compute `h_t = a_t * h_{t−1} + b_t` and `y_t = C_t h_t` in parallel.\n",
    "\n",
    "    Reference:\n",
    "    [Efficient Parallelization of a Ubiquitous Sequential Computation](https://arxiv.org/pdf/2311.06281.pdf)\n",
    "    \"\"\"\n",
    "    # Combine B_bar_x and h_t into a single tensor\n",
    "    B_bar_x = torch.cat([h_t[..., None], B_bar_x], dim=-1)  # [b x d x n x t + 1]\n",
    "\n",
    "    # Compute the log of the parameters in complex space as log of negative numbers is complex\n",
    "    log_A_bar = (\n",
    "        A_bar.masked_fill(A_bar == 0, eps).to(torch.complex64)\n",
    "    ).log()  # log a_t (eq. 2 - Efficient Parallelization)\n",
    "    log_B_bar_x = (\n",
    "        B_bar_x.masked_fill(B_bar_x == 0, eps).to(torch.complex64)\n",
    "    ).log()  # log b_t (eq. 2 - Efficient Parallelization)\n",
    "\n",
    "    # Compute the cumulative sum of log_A_bar along the time dimension\n",
    "    A_bar_star = F.pad(\n",
    "        torch.cumsum(log_A_bar, dim=-1), (1, 0)\n",
    "    )  # a_star_t (eq. 2 - Efficient Parallelization) [b x d x n x t + 1]\n",
    "\n",
    "    # Compute the log of the cumulative sum of log_B_bar_x along the time dimension\n",
    "    B_bar_x_star = torch.logcumsumexp(\n",
    "        log_B_bar_x - A_bar_star, dim=-1\n",
    "    )  # b_star_t (eq. 2 - Efficient Parallelization) [b x d x n x t + 1]\n",
    "\n",
    "    log_h_ts = (A_bar_star + B_bar_x_star)[\n",
    "        ..., 1:\n",
    "    ]  # log x_t (eq. 1 - Efficient Parallelization)\n",
    "    h_ts = torch.exp(\n",
    "        log_h_ts\n",
    "    ).real  # x_t (eq. 3 - Efficient Parallelization) h_t = ̄A_t h_t + ̄Bx_t (eq. 2a - Mamba)\n",
    "    print(h_ts.shape)\n",
    "    return torch.einsum(\"bnt,bdnt->bdt\", C, h_ts)  # y_t = C_t h_t  (eq. 2b - Mamba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_SSM(Ab, Bb, Cb, u, x0):\n",
    "    def step(x_k_1, u_k):\n",
    "        x_k = Ab @ x_k_1 + Bb @ u_k\n",
    "        y_k = Cb @ x_k\n",
    "        return x_k, y_k\n",
    "\n",
    "    return jax.lax.scan(step, x0, u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dimesnions  S4\n",
    " - Input(x) and output(y) are of size BLD\n",
    " - A : (DN)\n",
    " - B : (DN) \n",
    " - C : (DN)\n",
    " - Delta : (D)\n",
    " - A_BAR, B_BAR : (DN) discretize with (Delta,AB)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSM_S4(dt: torch.Tensor, h_t: torch.Tensor ,A : torch.Tensor, B: torch.Tensor, C: torch.Tensor):\n",
    "\n",
    "    dA = torch.exp(torch.einsum(\"d,dn-> dn\", dt, A))\n",
    "    print(\"dA:\", dA.shape)\n",
    "    dB_u = torch.einsum(\"d,dn,bld->bldn\",dt,B,h_t)\n",
    "    log_da = complex_log(dA)\n",
    "    print(\"dB_u:\", dB_u.shape)\n",
    "\n",
    "    log_dB_u = complex_log(dB_u)\n",
    "    print(\"log_da:\",log_da.shape)\n",
    "    print(\"log_dB_u:\",log_dB_u.shape)\n",
    "    a_star = F.pad(torch.cumsum(log_da,dim =-1),(0,0,0,1))\n",
    "    log_x0_plus_b_star = torch.logcumsumexp(log_dB_u - a_star, dim=-1)  \n",
    "    log_x = a_star + log_x0_plus_b_star                                   # eq (1) in paper\n",
    "    x = torch.exp(log_x).real\t\n",
    "    y = torch.einsum('blnn,dn->bld', x,C)\n",
    "    return y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_SSM_s4(A, B, C, u):\n",
    "    #L = u.shape[0]\n",
    "    #N = A.shape[0]\n",
    "    #Ab, Bb, Cb = discretize(A, B, C, step=1.0 / L)\n",
    "\n",
    "    # Run recurrence\n",
    "    return SSM_S4(Ab, Bb, Cb, u[:, np.newaxis], np.zeros((N,)))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_ssm_s4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 1\n",
    "n = 2\n",
    "b = 3\n",
    "l = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = torch.rand((d))\n",
    "A = torch.rand((d,n))\n",
    "B = torch.rand((d,n))\n",
    "C =  torch.rand((d,n))\n",
    "h_t =torch.rand(b,l,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA: torch.Size([1, 2])\n",
      "dB_u: torch.Size([3, 4, 1, 2])\n",
      "log_da: torch.Size([1, 2])\n",
      "log_dB_u: torch.Size([3, 4, 1, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSM_S4(dt,h_t,A,B,C ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_SSM(A : torch.Tensor, B : torch.Tensor, C : torch.Tensor, u : torch.Tensor):\n",
    "\n",
    "    #L = u.shape[0]\n",
    "    #N = A.shape[0]\n",
    "    dt = torch.rand((1))\n",
    "    #a_b , b_b , c_b = space.discretize(A,B,C,1.0/L)\n",
    "    return SSM_S4(dt,u, A,B,C)[1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA: torch.Size([1, 2])\n",
      "dB_u: torch.Size([3, 4, 1, 2])\n",
      "log_da: torch.Size([1, 2])\n",
      "log_dB_u: torch.Size([3, 4, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "y = run_SSM(A,B,C,h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4017762  0.5127762  0.0409007  0.15183365]\n"
     ]
    }
   ],
   "source": [
    "print(y.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0.,   1.],\n",
       "         [-40.,  -5.]]),\n",
       " tensor([[0.],\n",
       "         [1.]]),\n",
       " tensor([[1., 0.]]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_mass(k=40, b=5, m=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m example_force(\u001b[43mks\u001b[49m \u001b[38;5;241m*\u001b[39m step)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ks' is not defined"
     ]
    }
   ],
   "source": [
    "example_force(ks * step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOLVE PENDING DIMENSIONALTIY ISSUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5646, 0.6442, 0.7174,\n",
      "        0.7833, 0.8415, 0.8912, 0.9320, 0.9636, 0.9854, 0.9975, 0.9996, 0.9917,\n",
      "        0.9738, 0.9463, 0.9093, 0.8632, 0.8085, 0.7457, 0.6755, 0.5985, 0.5155,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "        -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "        -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "        -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5784, 0.6570, 0.7290,\n",
      "        0.7937, 0.8504, 0.8987, 0.9380, 0.9679, 0.9882, 0.9985, 0.9989, 0.9894,\n",
      "        0.9699, 0.9407, 0.9022, 0.8546, 0.7985, 0.7344, 0.6630, 0.5849, 0.5010,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "        -0.0000])\n",
      "dA: torch.Size([2, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "einsum(): the number of subscripts in the equation (3) does not match the number of dimensions (1) for operand 2 and no ellipsis was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(u)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Approximation of y(t).\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mrun_SSM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mssm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Plotting ---\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[70], line 7\u001b[0m, in \u001b[0;36mrun_SSM\u001b[1;34m(A, B, C, u)\u001b[0m\n\u001b[0;32m      5\u001b[0m dt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#a_b , b_b , c_b = space.discretize(A,B,C,1.0/L)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSSM_S4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43mC\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[1;32mIn[68], line 5\u001b[0m, in \u001b[0;36mSSM_S4\u001b[1;34m(dt, h_t, A, B, C)\u001b[0m\n\u001b[0;32m      3\u001b[0m dA \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md,dn-> dn\u001b[39m\u001b[38;5;124m\"\u001b[39m, dt, A))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdA:\u001b[39m\u001b[38;5;124m\"\u001b[39m, dA\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 5\u001b[0m dB_u \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43md,dn,bld->bldn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43mh_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m log_da \u001b[38;5;241m=\u001b[39m complex_log(dA)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdB_u:\u001b[39m\u001b[38;5;124m\"\u001b[39m, dB_u\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\Documents\\python_stuff\\venv\\Lib\\site-packages\\torch\\functional.py:377\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[1;32m--> 377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    379\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[1;31mRuntimeError\u001b[0m: einsum(): the number of subscripts in the equation (3) does not match the number of dimensions (1) for operand 2 and no ellipsis was given"
     ]
    }
   ],
   "source": [
    "ssm = example_mass(k=40, b=5, m=1)\n",
    "\n",
    "# L samples of u(t).\n",
    "L = 100\n",
    "step = 1.0 / L\n",
    "ks = np.arange(L)\n",
    "u = example_force(ks * step)\n",
    "print(u)\n",
    "# Approximation of y(t).\n",
    "y = run_SSM(*ssm, u).reshape(-1)\n",
    "print\n",
    "# Plotting ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from celluloid import Camera\n",
    "\n",
    "seaborn.set_context(\"paper\")\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3)\n",
    "camera = Camera(fig)\n",
    "ax1.set_title(\"Force $u_k$\")\n",
    "ax2.set_title(\"Position $y_k$\")\n",
    "#ax3.set_title(\"Object\")\n",
    "ax1.set_xticks([], [])\n",
    "ax2.set_xticks([], [])\n",
    "\n",
    "# Animate plot over time\n",
    "for k in range(0, L, 2):\n",
    "    print(y[:k])\n",
    "    ax1.plot(ks[:k], u[:k], color=\"red\")\n",
    "    ax2.plot(ks[:k], y[:k], color=\"blue\")\n",
    "    # ax3.boxplot(\n",
    "    #     [[y[k, 0] - 0.04, y[k, 0], y[k, 0] + 0.04]],\n",
    "    #     showcaps=False,\n",
    "    #     whis=False,\n",
    "    #     vert=False,\n",
    "    #     widths=10,\n",
    "    # )\n",
    "    camera.snap()\n",
    "anim = camera.animate()\n",
    "anim.save(\"line.gif\", dpi=150, writer=\"imagemagick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_ssm():\n",
    "    # SSM\n",
    "    ssm = example_mass(k=40, b=5, m=1)\n",
    "\n",
    "    # L samples of u(t).\n",
    "    L = 100\n",
    "    step = 1.0 / L\n",
    "    ks = np.arange(L)\n",
    "    u = example_force(ks * step)\n",
    "\n",
    "    # Approximation of y(t).\n",
    "    y = run_SSM(*ssm, u)\n",
    "    print\n",
    "    # Plotting ---\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn\n",
    "    from celluloid import Camera\n",
    "\n",
    "    seaborn.set_context(\"paper\")\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3)\n",
    "    camera = Camera(fig)\n",
    "    ax1.set_title(\"Force $u_k$\")\n",
    "    ax2.set_title(\"Position $y_k$\")\n",
    "    ax3.set_title(\"Object\")\n",
    "    ax1.set_xticks([], [])\n",
    "    ax2.set_xticks([], [])\n",
    "\n",
    "    # Animate plot over time\n",
    "    for k in range(0, L, 2):\n",
    "        ax1.plot(ks[:k], u[:k], color=\"red\")\n",
    "        ax2.plot(ks[:k], y[:k], color=\"blue\")\n",
    "        ax3.boxplot(\n",
    "            [[y[k, 0] - 0.04, y[k, 0], y[k, 0] + 0.04]],\n",
    "            showcaps=False,\n",
    "            whis=False,\n",
    "            vert=False,\n",
    "            widths=10,\n",
    "        )\n",
    "        camera.snap()\n",
    "    anim = camera.animate()\n",
    "    anim.save(\"line.gif\", dpi=150, writer=\"imagemagick\")\n",
    "if False:\n",
    "    example_ssm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 2])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mexample_ssm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[67], line 33\u001b[0m, in \u001b[0;36mexample_ssm\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     ax1\u001b[38;5;241m.\u001b[39mplot(ks[:k], u[:k], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m     ax2\u001b[38;5;241m.\u001b[39mplot(ks[:k], y[:k], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m     ax3\u001b[38;5;241m.\u001b[39mboxplot(\n\u001b[1;32m---> 33\u001b[0m         [[\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.04\u001b[39m, y[k, \u001b[38;5;241m0\u001b[39m], y[k, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.04\u001b[39m]],\n\u001b[0;32m     34\u001b[0m         showcaps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     35\u001b[0m         whis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     36\u001b[0m         vert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     37\u001b[0m         widths\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     38\u001b[0m     )\n\u001b[0;32m     39\u001b[0m     camera\u001b[38;5;241m.\u001b[39msnap()\n\u001b[0;32m     40\u001b[0m anim \u001b[38;5;241m=\u001b[39m camera\u001b[38;5;241m.\u001b[39manimate()\n",
      "\u001b[1;31mTypeError\u001b[0m: tuple indices must be integers or slices, not tuple"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_ssm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
